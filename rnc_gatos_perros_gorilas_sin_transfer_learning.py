# -*- coding: utf-8 -*-
"""rnc_gatos_perros_gorilas_sin_transfer_learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lqVM6Okwr1KI7YI9dMXF84AatDkcLQrJ
"""

from google.colab import drive

#mount drive
drive.mount('/content/drive')
#locate the file in google drive
path = '/drive/My Drive/dataset_gatos_perros_gorilas'

#show numbers image every class
!ls /content/drive/MyDrive/dataset_gatos_perros_gorilas/gato// | wc -l
!ls /content/drive/MyDrive/dataset_gatos_perros_gorilas/gorila// | wc -l
!ls /content/drive/MyDrive/dataset_gatos_perros_gorilas/perro/ | wc -l

#show some image from folder
import os
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

plt.figure(figsize=(15,15))
gatos = '/content/drive/MyDrive/dataset_gatos_perros_gorilas/gato/'
imgs = os.listdir(gatos)

for i, nameimg in enumerate(imgs[:25]):
  plt.subplot(5,5,i+1)
  img = mpimg.imread(gatos + '/' + nameimg)
  plt.imshow(img)

#data augmentations with ImageDataGenerator
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np

#create data generator
datagen = ImageDataGenerator(
    rescale = 1. /255, #val between 0 and 1, not between 0 and 255
    rotation_range = 30,
    width_shift_range = 0.25,
    height_shift_range = 0.25,
    shear_range = 15,
    zoom_range = [0.5, 1.5],
    validation_split = 0.2 #20% for data test
)

#generators for training and validation data
datagen_training = datagen.flow_from_directory('/content/drive/MyDrive/dataset_gatos_perros_gorilas/', 
                                               target_size = (224,224), batch_size = 32,
                                               shuffle = True, subset = 'training'
                                               )
datagen_validation = datagen.flow_from_directory('/content/drive/MyDrive/dataset_gatos_perros_gorilas/', 
                                               target_size = (224,224), batch_size = 32,
                                               shuffle = True, subset = 'validation'
                                               )
#print 10 image from training subset
for image, label in datagen_training:
  for i in range(10):
    plt.subplot(2,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(image[i])
  break
plt.show()

import tensorflow as tf
modelo = tf.keras.models.Sequential([
  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(32, activation='relu'),
  tf.keras.layers.Dense(3, activation='softmax') # 3 clases
])
modelo.build([None, 224, 224, 3])  # Batch input shape.
modelo.summary()

modelo.compile(
    optimizer = 'adam',
    loss = 'categorical_crossentropy',
    metrics = ['accuracy']
)

#training model with generators of training and validations
EPOCHS = 50
historial = modelo.fit(
    datagen_training, epochs = EPOCHS, batch_size = 32,
    validation_data = datagen_validation
)

#precision graphics
acc = historial.history['accuracy']
val_acc = historial.history['val_accuracy']

loss = historial.history['loss']
val_loss = historial.history['val_loss']

rango_epocas = range(50)

plt.figure(figsize=(8,8))
plt.subplot(1,2,1)
plt.plot(rango_epocas, acc, label='Precisión Entrenamiento')
plt.plot(rango_epocas, val_acc, label='Precisión Pruebas')
plt.legend(loc='lower right')
plt.title('Precisión de entrenamiento y pruebas')

plt.subplot(1,2,2)
plt.plot(rango_epocas, loss, label='Pérdida de entrenamiento')
plt.plot(rango_epocas, val_loss, label='Pérdida de pruebas')
plt.legend(loc='upper right')
plt.title('Pérdida de entrenamiento y pruebas')
plt.show()

from PIL import Image
import requests
from io import BytesIO
import cv2

def categorizar(url):
  response = requests.get(url)
  img = Image.open(BytesIO(response.content))
  img = np.array(img).astype(float)/255

  img = cv2.resize(img, (224,224))
  prediction = modelo.predict(img.reshape(-1,224,224,3))
  return np.argmax(prediction[0], axis = -1)

#0 gatos, 1 gorilas, 2 perros
url_gor1 = 'https://images.pexels.com/photos/1851537/pexels-photo-1851537.jpeg'
url_gat1 = 'https://images.pexels.com/photos/1543793/pexels-photo-1543793.jpeg'
url_gat2 = 'https://images.pexels.com/photos/1170986/pexels-photo-1170986.jpeg'
url_gor2 = 'https://images.pexels.com/photos/46317/pexels-photo-46317.jpeg'
url_per1 = 'https://images.pexels.com/photos/2253275/pexels-photo-2253275.jpeg'
url_per2 = 'https://images.pexels.com/photos/2007/animal-dog-pet-cute.jpg'

prediction_gat1 = categorizar(url_gat1)
print(prediction_gat1)
prediction_gor1 = categorizar(url_gor1)
print(prediction_gor1)
prediction_per1 = categorizar(url_per1)
print(prediction_per1)
prediction_gat2 = categorizar(url_gat2)
print(prediction_gat2)
prediction_gor2 = categorizar(url_gor2)
print(prediction_gor2)
prediction_per2 = categorizar(url_per2)
print(prediction_per2)

#save model h5 format
modelo.save('rnc_perros_gatos_gorilas.h5')

#transform model to tensorflow.js
!pip install tensorflowjs

#create folder to convert
!mkdir convertjs_folder

#to do the convertion
!tensorflowjs_converter --input_format keras rnc_perros_gatos_gorilas.h5 convertjs_folder

#review content to folder and download to pc
!ls convertjs_folder